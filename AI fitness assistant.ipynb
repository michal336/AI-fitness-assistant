{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0. import potrzebnych bibliotek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pozycje stawów i kończyn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. tworzenie baz do uczenia modelu ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) tworzenie bazy z danymi z filmów z uginania ramion do uczenia modelu ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr={'x_shoulder_left':[],'y_shoulder_left':[],'z_shoulder_left':[],\n",
    "        'x_shoulder_right':[],'y_shoulder_right':[],'z_shoulder_right':[],\n",
    "        'x_elbow_left':[],'x_elbow_left':[],'x_elbow_left':[],\n",
    "        'x_elbow_right':[],'y_elbow_right':[],'x_elbow_right':[],\n",
    "        'x_wrist_left':[],'x_wrist_left':[],'x_wrist_left':[],\n",
    "        'x_wrist_right':[],'y_wrist_right':[],'x_wrist_right':[],\n",
    "        'state':[]}\n",
    "\n",
    "curl_dataframe=pd.DataFrame(dfr)\n",
    "curl_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(curl_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#wczytywanie danych z nagrania (pozycja górna)\n",
    "cap = cv2.VideoCapture('curl-up.mp4')\n",
    "## Setup mediapipe instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "      \n",
    "            # Make detection\n",
    "            position = pose.process(image)\n",
    "    \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #save_positon(position)\n",
    "            df2={'x_shoulder_left':position.pose_landmarks.landmark[11].x,'y_shoulder_left':position.pose_landmarks.landmark[11].y,'z_shoulder_left':position.pose_landmarks.landmark[11].z,\n",
    "            'x_shoulder_right':position.pose_landmarks.landmark[12].x,'y_shoulder_right':position.pose_landmarks.landmark[12].y,'z_shoulder_right':position.pose_landmarks.landmark[12].z,\n",
    "            'x_elbow_left':position.pose_landmarks.landmark[13].x,'y_elbow_left':position.pose_landmarks.landmark[13].y,'z_elbow_left':position.pose_landmarks.landmark[13].z,\n",
    "            'x_elbow_right':position.pose_landmarks.landmark[14].x,'y_elbow_right':position.pose_landmarks.landmark[14].y,'z_elbow_right':position.pose_landmarks.landmark[14].z,\n",
    "            'x_wrist_left':position.pose_landmarks.landmark[15].x,'y_wrist_left':position.pose_landmarks.landmark[15].y,'z_wrist_left':position.pose_landmarks.landmark[15].z,\n",
    "            'x_wrist_right':position.pose_landmarks.landmark[16].x,'y_wrist_right':position.pose_landmarks.landmark[16].y,'z_wrist_right':position.pose_landmarks.landmark[16].z,\n",
    "            'state':'up'}\n",
    "            curl_dataframe=curl_dataframe._append(df2, ignore_index = True)\n",
    "\n",
    "        \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, position.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "        \n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wczytywanie danych z nagrania (pozycja dolna)\n",
    "cap = cv2.VideoCapture('curl-down.mp4')\n",
    "## Setup mediapipe instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "      \n",
    "            # Make detection\n",
    "            position = pose.process(image)\n",
    "    \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #save_positon(position)\n",
    "            df2={'x_shoulder_left':position.pose_landmarks.landmark[11].x,'y_shoulder_left':position.pose_landmarks.landmark[11].y,'z_shoulder_left':position.pose_landmarks.landmark[11].z,\n",
    "            'x_shoulder_right':position.pose_landmarks.landmark[12].x,'y_shoulder_right':position.pose_landmarks.landmark[12].y,'z_shoulder_right':position.pose_landmarks.landmark[12].z,\n",
    "            'x_elbow_left':position.pose_landmarks.landmark[13].x,'y_elbow_left':position.pose_landmarks.landmark[13].y,'z_elbow_left':position.pose_landmarks.landmark[13].z,\n",
    "            'x_elbow_right':position.pose_landmarks.landmark[14].x,'y_elbow_right':position.pose_landmarks.landmark[14].y,'z_elbow_right':position.pose_landmarks.landmark[14].z,\n",
    "            'x_wrist_left':position.pose_landmarks.landmark[15].x,'y_wrist_left':position.pose_landmarks.landmark[15].y,'z_wrist_left':position.pose_landmarks.landmark[15].z,\n",
    "            'x_wrist_right':position.pose_landmarks.landmark[16].x,'y_wrist_right':position.pose_landmarks.landmark[16].y,'z_wrist_right':position.pose_landmarks.landmark[16].z,\n",
    "            'state':'down'}\n",
    "            curl_dataframe=curl_dataframe._append(df2, ignore_index = True)\n",
    "\n",
    "        \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, position.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "        \n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(curl_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) tworzenie bazy z danymi z filmów z przysiadów do uczenia modelu ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = {\n",
    "    'x_shoulder_left': [], 'y_shoulder_left': [], 'z_shoulder_left': [],\n",
    "    'x_shoulder_right': [], 'y_shoulder_right': [], 'z_shoulder_right': [],\n",
    "    'x_hip_left': [], 'y_hip_left': [], 'z_hip_left': [],\n",
    "    'x_hip_right': [], 'y_hip_right': [], 'z_hip_right': [],\n",
    "    'x_knee_left': [], 'y_knee_left': [], 'z_knee_left': [],\n",
    "    'x_knee_right': [], 'y_knee_right': [], 'z_knee_right': [],\n",
    "    'x_ankle_left': [], 'y_ankle_left': [], 'z_ankle_left': [],\n",
    "    'x_ankle_right': [], 'y_ankle_right': [], 'z_ankle_right': [],\n",
    "    'state': []\n",
    "}\n",
    "\n",
    "squat_dataframe=pd.DataFrame(dfr)\n",
    "squat_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "squat_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wczytywanie danych z nagrania (pozycja górna)\n",
    "cap = cv2.VideoCapture('squat-up.mp4')\n",
    "## Setup mediapipe instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "      \n",
    "            # Make detection\n",
    "            position = pose.process(image)\n",
    "    \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #save_positon(position)\n",
    "            df2 = {\n",
    "    'x_shoulder_left': position.pose_landmarks.landmark[11].x,\n",
    "    'y_shoulder_left': position.pose_landmarks.landmark[11].y,\n",
    "    'z_shoulder_left': position.pose_landmarks.landmark[11].z,\n",
    "    'x_shoulder_right': position.pose_landmarks.landmark[12].x,\n",
    "    'y_shoulder_right': position.pose_landmarks.landmark[12].y,\n",
    "    'z_shoulder_right': position.pose_landmarks.landmark[12].z,\n",
    "    'x_hip_left': position.pose_landmarks.landmark[23].x,  \n",
    "    'y_hip_left': position.pose_landmarks.landmark[23].y,\n",
    "    'z_hip_left': position.pose_landmarks.landmark[23].z,\n",
    "    'x_hip_right': position.pose_landmarks.landmark[24].x,\n",
    "    'y_hip_right': position.pose_landmarks.landmark[24].y,\n",
    "    'z_hip_right': position.pose_landmarks.landmark[24].z,\n",
    "    'x_knee_left': position.pose_landmarks.landmark[25].x,  \n",
    "    'y_knee_left': position.pose_landmarks.landmark[25].y,\n",
    "    'z_knee_left': position.pose_landmarks.landmark[25].z,\n",
    "    'x_knee_right': position.pose_landmarks.landmark[26].x,\n",
    "    'y_knee_right': position.pose_landmarks.landmark[26].y,\n",
    "    'z_knee_right': position.pose_landmarks.landmark[26].z,\n",
    "    'x_ankle_left': position.pose_landmarks.landmark[27].x,  \n",
    "    'y_ankle_left': position.pose_landmarks.landmark[27].y,\n",
    "    'z_ankle_left': position.pose_landmarks.landmark[27].z,\n",
    "    'x_ankle_right': position.pose_landmarks.landmark[28].x,\n",
    "    'y_ankle_right': position.pose_landmarks.landmark[28].y,\n",
    "    'z_ankle_right': position.pose_landmarks.landmark[28].z,\n",
    "    'state': 'up'\n",
    "}\n",
    "            squat_dataframe=squat_dataframe._append(df2, ignore_index = True)\n",
    "\n",
    "        \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, position.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "        \n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wczytywanie danych z nagrania (pozycja dolna)\n",
    "cap = cv2.VideoCapture('squat-down.mp4')\n",
    "## Setup mediapipe instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "      \n",
    "            # Make detection\n",
    "            position = pose.process(image)\n",
    "    \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #save_positon(position)\n",
    "            df2 = {\n",
    "    'x_shoulder_left': position.pose_landmarks.landmark[11].x,\n",
    "    'y_shoulder_left': position.pose_landmarks.landmark[11].y,\n",
    "    'z_shoulder_left': position.pose_landmarks.landmark[11].z,\n",
    "    'x_shoulder_right': position.pose_landmarks.landmark[12].x,\n",
    "    'y_shoulder_right': position.pose_landmarks.landmark[12].y,\n",
    "    'z_shoulder_right': position.pose_landmarks.landmark[12].z,\n",
    "    'x_hip_left': position.pose_landmarks.landmark[23].x,  \n",
    "    'y_hip_left': position.pose_landmarks.landmark[23].y,\n",
    "    'z_hip_left': position.pose_landmarks.landmark[23].z,\n",
    "    'x_hip_right': position.pose_landmarks.landmark[24].x,\n",
    "    'y_hip_right': position.pose_landmarks.landmark[24].y,\n",
    "    'z_hip_right': position.pose_landmarks.landmark[24].z,\n",
    "    'x_knee_left': position.pose_landmarks.landmark[25].x,  \n",
    "    'y_knee_left': position.pose_landmarks.landmark[25].y,\n",
    "    'z_knee_left': position.pose_landmarks.landmark[25].z,\n",
    "    'x_knee_right': position.pose_landmarks.landmark[26].x,\n",
    "    'y_knee_right': position.pose_landmarks.landmark[26].y,\n",
    "    'z_knee_right': position.pose_landmarks.landmark[26].z,\n",
    "    'x_ankle_left': position.pose_landmarks.landmark[27].x,  \n",
    "    'y_ankle_left': position.pose_landmarks.landmark[27].y,\n",
    "    'z_ankle_left': position.pose_landmarks.landmark[27].z,\n",
    "    'x_ankle_right': position.pose_landmarks.landmark[28].x,\n",
    "    'y_ankle_right': position.pose_landmarks.landmark[28].y,\n",
    "    'z_ankle_right': position.pose_landmarks.landmark[28].z,\n",
    "    'state': 'down'\n",
    "}\n",
    "            squat_dataframe=squat_dataframe._append(df2, ignore_index = True)\n",
    "\n",
    "        \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, position.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "        \n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(squat_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) tworzenie bazy z danymi z filmów z martwych ciągów do uczenia modelu ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = {\n",
    "    'x_shoulder_left': [], 'y_shoulder_left': [], 'z_shoulder_left': [],\n",
    "    'x_shoulder_right': [], 'y_shoulder_right': [], 'z_shoulder_right': [],\n",
    "    'x_hip_left': [], 'y_hip_left': [], 'z_hip_left': [],\n",
    "    'x_hip_right': [], 'y_hip_right': [], 'z_hip_right': [],\n",
    "    'x_knee_left': [], 'y_knee_left': [], 'z_knee_left': [],\n",
    "    'x_knee_right': [], 'y_knee_right': [], 'z_knee_right': [],\n",
    "    'x_ankle_left': [], 'y_ankle_left': [], 'z_ankle_left': [],\n",
    "    'x_ankle_right': [], 'y_ankle_right': [], 'z_ankle_right': [],\n",
    "    'state': []\n",
    "}\n",
    "\n",
    "dl_dataframe=pd.DataFrame(dfr)\n",
    "dl_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wczytywanie danych z nagrania (pozycja górna)\n",
    "cap = cv2.VideoCapture('dl-up.mp4')\n",
    "## Setup mediapipe instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "      \n",
    "            # Make detection\n",
    "            position = pose.process(image)\n",
    "    \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #save_positon(position)\n",
    "            df2 = {\n",
    "    'x_shoulder_left': position.pose_landmarks.landmark[11].x,\n",
    "    'y_shoulder_left': position.pose_landmarks.landmark[11].y,\n",
    "    'z_shoulder_left': position.pose_landmarks.landmark[11].z,\n",
    "    'x_shoulder_right': position.pose_landmarks.landmark[12].x,\n",
    "    'y_shoulder_right': position.pose_landmarks.landmark[12].y,\n",
    "    'z_shoulder_right': position.pose_landmarks.landmark[12].z,\n",
    "    'x_hip_left': position.pose_landmarks.landmark[23].x,  \n",
    "    'y_hip_left': position.pose_landmarks.landmark[23].y,\n",
    "    'z_hip_left': position.pose_landmarks.landmark[23].z,\n",
    "    'x_hip_right': position.pose_landmarks.landmark[24].x,\n",
    "    'y_hip_right': position.pose_landmarks.landmark[24].y,\n",
    "    'z_hip_right': position.pose_landmarks.landmark[24].z,\n",
    "    'x_knee_left': position.pose_landmarks.landmark[25].x,  \n",
    "    'y_knee_left': position.pose_landmarks.landmark[25].y,\n",
    "    'z_knee_left': position.pose_landmarks.landmark[25].z,\n",
    "    'x_knee_right': position.pose_landmarks.landmark[26].x,\n",
    "    'y_knee_right': position.pose_landmarks.landmark[26].y,\n",
    "    'z_knee_right': position.pose_landmarks.landmark[26].z,\n",
    "    'x_ankle_left': position.pose_landmarks.landmark[27].x,  \n",
    "    'y_ankle_left': position.pose_landmarks.landmark[27].y,\n",
    "    'z_ankle_left': position.pose_landmarks.landmark[27].z,\n",
    "    'x_ankle_right': position.pose_landmarks.landmark[28].x,\n",
    "    'y_ankle_right': position.pose_landmarks.landmark[28].y,\n",
    "    'z_ankle_right': position.pose_landmarks.landmark[28].z,\n",
    "    'state': 'up'\n",
    "}\n",
    "            dl_dataframe=dl_dataframe._append(df2, ignore_index = True)\n",
    "\n",
    "        \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, position.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "        \n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#wczytywanie danych z nagrania (pozycja rodkowa)\n",
    "cap = cv2.VideoCapture('dl-down.mp4')\n",
    "## Setup mediapipe instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "      \n",
    "            # Make detection\n",
    "            position = pose.process(image)\n",
    "    \n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #save_positon(position)\n",
    "            df2 = {\n",
    "    'x_shoulder_left': position.pose_landmarks.landmark[11].x,\n",
    "    'y_shoulder_left': position.pose_landmarks.landmark[11].y,\n",
    "    'z_shoulder_left': position.pose_landmarks.landmark[11].z,\n",
    "    'x_shoulder_right': position.pose_landmarks.landmark[12].x,\n",
    "    'y_shoulder_right': position.pose_landmarks.landmark[12].y,\n",
    "    'z_shoulder_right': position.pose_landmarks.landmark[12].z,\n",
    "    'x_hip_left': position.pose_landmarks.landmark[23].x,  \n",
    "    'y_hip_left': position.pose_landmarks.landmark[23].y,\n",
    "    'z_hip_left': position.pose_landmarks.landmark[23].z,\n",
    "    'x_hip_right': position.pose_landmarks.landmark[24].x,\n",
    "    'y_hip_right': position.pose_landmarks.landmark[24].y,\n",
    "    'z_hip_right': position.pose_landmarks.landmark[24].z,\n",
    "    'x_knee_left': position.pose_landmarks.landmark[25].x,  \n",
    "    'y_knee_left': position.pose_landmarks.landmark[25].y,\n",
    "    'z_knee_left': position.pose_landmarks.landmark[25].z,\n",
    "    'x_knee_right': position.pose_landmarks.landmark[26].x,\n",
    "    'y_knee_right': position.pose_landmarks.landmark[26].y,\n",
    "    'z_knee_right': position.pose_landmarks.landmark[26].z,\n",
    "    'x_ankle_left': position.pose_landmarks.landmark[27].x,  \n",
    "    'y_ankle_left': position.pose_landmarks.landmark[27].y,\n",
    "    'z_ankle_left': position.pose_landmarks.landmark[27].z,\n",
    "    'x_ankle_right': position.pose_landmarks.landmark[28].x,\n",
    "    'y_ankle_right': position.pose_landmarks.landmark[28].y,\n",
    "    'z_ankle_right': position.pose_landmarks.landmark[28].z,\n",
    "    'state': 'down'\n",
    "}\n",
    "            dl_dataframe=dl_dataframe._append(df2, ignore_index = True)\n",
    "\n",
    "        \n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, position.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "        \n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dl_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. trenowanie modelu ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bibliotek p[otrzebnych do tworzenia modelów\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) trenowanie modelu do sledzenia uginania ramion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=curl_dataframe.drop(['state'],axis=1)\n",
    "y=curl_dataframe['state']\n",
    "y=pd.get_dummies(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "macierz_korelacji = pd.get_dummies(curl_dataframe).corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(macierz_korelacji, annot=True, cmap=\"RdYlBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilacja modelu\n",
    "\n",
    "model_curl = Sequential()\n",
    "model_curl.add(Dense(128, activation='relu', ))\n",
    "model_curl.add(Dense(128, activation='relu'))\n",
    "model_curl.add(Dense(2, activation='sigmoid'))\n",
    "model_curl.compile(loss=BinaryCrossentropy(from_logits=True), optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trenowanie modelu\n",
    "model_curl.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sprawdzanie modelu \n",
    "y_hat=model_curl.predict(X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) trenowanie modelu do sledzenia przysiadów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zapisywanie modelu\n",
    "model_curl.save('model_curl.keras')\n",
    "model_curl.save('model_curl.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=squat_dataframe.drop(['state'],axis=1)\n",
    "y=squat_dataframe['state']\n",
    "y=pd.get_dummies(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilacja modelu\n",
    "\n",
    "model_squat = Sequential()\n",
    "model_squat.add(Dense(128, activation='relu', ))\n",
    "model_squat.add(Dense(128, activation='relu'))\n",
    "model_squat.add(Dense(2, activation='sigmoid'))\n",
    "model_squat.compile(loss=BinaryCrossentropy(from_logits=True), optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trenowanie modelu\n",
    "model_squat.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "macierz_korelacji = pd.get_dummies(squat_dataframe).corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(macierz_korelacji, annot=True, cmap=\"RdYlBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Kompilacja modelu\n",
    "\n",
    "model_squat = Sequential()\n",
    "model_squat.add(Dense(128, activation='relu', ))\n",
    "model_squat.add(Dense(128, activation='relu'))\n",
    "model_squat.add(Dense(2, activation='sigmoid'))\n",
    "model_squat.compile(loss=BinaryCrossentropy(from_logits=True), optimizer=Adam(), metrics=['accuracy'])\n",
    "#trenowanie modelu\n",
    "model_squat.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sprawdzanie modelu \n",
    "y_hat=model_curl.predict(X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zapisywanie modelu\n",
    "model_squat.save('model_squat.keras')\n",
    "model_squat.save('model_squat.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) trenowanie modelu do sledzenia martwych ciągów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dl_dataframe.drop(['state'],axis=1)\n",
    "y=dl_dataframe['state']\n",
    "y=pd.get_dummies(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kompilacja modelu\n",
    "\n",
    "model_dl = Sequential()\n",
    "model_dl.add(Dense(128, activation='relu', ))\n",
    "model_dl.add(Dense(128, activation='relu'))\n",
    "model_dl.add(Dense(2, activation='sigmoid'))\n",
    "model_dl.compile(loss=BinaryCrossentropy(from_logits=True), optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trenowanie modelu\n",
    "model_dl.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_hat3=model_dl.predict(X_test)\n",
    "y_hat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zapisywanie modeli\n",
    "model_squat.save('model_squat.h5')\n",
    "model_squat.save('model_squat.keras')\n",
    "model_curl.save('model_curl.h5')\n",
    "model_curl.save('model_curl.keras')\n",
    "model_dl.save('model_dl.h5')\n",
    "model_dl.save('model_dl.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Licznik powtórzeń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#wczytywanie modeli\n",
    "\n",
    "model_squat=load_model('model_squat.keras')\n",
    "\n",
    "model_curl=load_model('model_curl.keras')\n",
    "\n",
    "model_dl=load_model('model_dl.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state=\"none\"\n",
    "down=0\n",
    "middle=0\n",
    "up=0\n",
    "excrs=1\n",
    "curls_reps=0\n",
    "squat_reps=0\n",
    "dl_reps=0\n",
    "#wczytywanie danych z nagrania (pozycja górna)\n",
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "            # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "    \n",
    "            # Make detection\n",
    "        position = pose.process(image)\n",
    "    \n",
    "            # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            #save_positon(position)\n",
    "\n",
    "        if excrs==1:\n",
    "            try:\n",
    "                df2 = pd.DataFrame({\n",
    "                    'x_shoulder_left': [position.pose_landmarks.landmark[11].x],\n",
    "                    'y_shoulder_left': [position.pose_landmarks.landmark[11].y],\n",
    "                    'z_shoulder_left': [position.pose_landmarks.landmark[11].z],\n",
    "                    'x_shoulder_right': [position.pose_landmarks.landmark[12].x],\n",
    "                    'y_shoulder_right': [position.pose_landmarks.landmark[12].y],\n",
    "                    'z_shoulder_right': [position.pose_landmarks.landmark[12].z],\n",
    "                    'x_elbow_left': [position.pose_landmarks.landmark[13].x],\n",
    "                    'x_elbow_right': [position.pose_landmarks.landmark[14].x],\n",
    "                    'y_elbow_right': [position.pose_landmarks.landmark[14].y],\n",
    "                    'x_wrist_left': [position.pose_landmarks.landmark[15].x],\n",
    "                    'x_wrist_right': [position.pose_landmarks.landmark[16].x],\n",
    "                    'y_wrist_right': [position.pose_landmarks.landmark[16].y],\n",
    "                    'y_elbow_left': [position.pose_landmarks.landmark[13].y],\n",
    "                    'z_elbow_left': [position.pose_landmarks.landmark[13].z],\n",
    "                    'z_elbow_right': [position.pose_landmarks.landmark[14].z],\n",
    "                    'y_wrist_left': [position.pose_landmarks.landmark[15].y],\n",
    "                    'z_wrist_left': [position.pose_landmarks.landmark[15].z],\n",
    "                    'z_wrist_right': [position.pose_landmarks.landmark[16].z]\n",
    "                    })\n",
    "                result=model_curl.predict(df2)\n",
    "                result=result[0]\n",
    "                down=round(result[0],2)\n",
    "                up=round(result[1],2)\n",
    "                if down>up:\n",
    "                    state=\"down\"\n",
    "                elif state==\"down\":\n",
    "                    state=\"up\"\n",
    "                    curls_reps+=1\n",
    "                \n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            cv2.putText(image, \"bicep curls\", \n",
    "                           (460,20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            cv2.putText(image, str(curls_reps), \n",
    "                           (500,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "\n",
    "            \n",
    "            \n",
    "        if excrs==2:\n",
    "            try:\n",
    "                df2 = pd.DataFrame({\n",
    "    'x_shoulder_left': [position.pose_landmarks.landmark[11].x],\n",
    "    'y_shoulder_left':[position.pose_landmarks.landmark[11].y],\n",
    "    'z_shoulder_left': [position.pose_landmarks.landmark[11].z],\n",
    "    'x_shoulder_right': [position.pose_landmarks.landmark[12].x],\n",
    "    'y_shoulder_right': [position.pose_landmarks.landmark[12].y],\n",
    "    'z_shoulder_right': [position.pose_landmarks.landmark[12].z],\n",
    "    'x_hip_left': [position.pose_landmarks.landmark[23].x],  \n",
    "    'y_hip_left': [position.pose_landmarks.landmark[23].y],\n",
    "    'z_hip_left': [position.pose_landmarks.landmark[23].z],\n",
    "    'x_hip_right': [position.pose_landmarks.landmark[24].x],\n",
    "    'y_hip_right': [position.pose_landmarks.landmark[24].y],\n",
    "    'z_hip_right': [position.pose_landmarks.landmark[24].z],\n",
    "    'x_knee_left': [position.pose_landmarks.landmark[25].x],  \n",
    "    'y_knee_left': [position.pose_landmarks.landmark[25].y],\n",
    "    'z_knee_left': [position.pose_landmarks.landmark[25].z],\n",
    "    'x_knee_right': [position.pose_landmarks.landmark[26].x],\n",
    "    'y_knee_right': [position.pose_landmarks.landmark[26].y],\n",
    "    'z_knee_right': [position.pose_landmarks.landmark[26].z],\n",
    "    'x_ankle_left': [position.pose_landmarks.landmark[27].x],  \n",
    "    'y_ankle_left': [position.pose_landmarks.landmark[27].y],\n",
    "    'z_ankle_left': [position.pose_landmarks.landmark[27].z],\n",
    "    'x_ankle_right': [position.pose_landmarks.landmark[28].x],\n",
    "    'y_ankle_right': [position.pose_landmarks.landmark[28].y],\n",
    "    'z_ankle_right': [position.pose_landmarks.landmark[28].z],\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                result=model_squat.predict(df2)\n",
    "                result=result[0]\n",
    "                down=round(result[0],2)\n",
    "                up=round(result[1],2)\n",
    "                if up>down:\n",
    "                    state=\"up\"\n",
    "                elif state==\"up\":\n",
    "                    state=\"down\"\n",
    "                    squat_reps+=1\n",
    "                \n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            cv2.putText(image, \"squat\", \n",
    "                           (460,20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            cv2.putText(image, str(squat_reps), \n",
    "                           (500,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "        if excrs==3:\n",
    "            try:\n",
    "                df2 = pd.DataFrame({\n",
    "    'x_shoulder_left': [position.pose_landmarks.landmark[11].x],\n",
    "    'y_shoulder_left':[position.pose_landmarks.landmark[11].y],\n",
    "    'z_shoulder_left': [position.pose_landmarks.landmark[11].z],\n",
    "    'x_shoulder_right': [position.pose_landmarks.landmark[12].x],\n",
    "    'y_shoulder_right': [position.pose_landmarks.landmark[12].y],\n",
    "    'z_shoulder_right': [position.pose_landmarks.landmark[12].z],\n",
    "    'x_hip_left': [position.pose_landmarks.landmark[23].x],  \n",
    "    'y_hip_left': [position.pose_landmarks.landmark[23].y],\n",
    "    'z_hip_left': [position.pose_landmarks.landmark[23].z],\n",
    "    'x_hip_right': [position.pose_landmarks.landmark[24].x],\n",
    "    'y_hip_right': [position.pose_landmarks.landmark[24].y],\n",
    "    'z_hip_right': [position.pose_landmarks.landmark[24].z],\n",
    "    'x_knee_left': [position.pose_landmarks.landmark[25].x],  \n",
    "    'y_knee_left': [position.pose_landmarks.landmark[25].y],\n",
    "    'z_knee_left': [position.pose_landmarks.landmark[25].z],\n",
    "    'x_knee_right': [position.pose_landmarks.landmark[26].x],\n",
    "    'y_knee_right': [position.pose_landmarks.landmark[26].y],\n",
    "    'z_knee_right': [position.pose_landmarks.landmark[26].z],\n",
    "    'x_ankle_left': [position.pose_landmarks.landmark[27].x],  \n",
    "    'y_ankle_left': [position.pose_landmarks.landmark[27].y],\n",
    "    'z_ankle_left': [position.pose_landmarks.landmark[27].z],\n",
    "    'x_ankle_right': [position.pose_landmarks.landmark[28].x],\n",
    "    'y_ankle_right': [position.pose_landmarks.landmark[28].y],\n",
    "    'z_ankle_right': [position.pose_landmarks.landmark[28].z],\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                result=model_dl.predict(df2)\n",
    "                result=result[0]\n",
    "                down=round(result[0],2)\n",
    "                up=round(result[1],2)\n",
    "                if up>down:\n",
    "                    state=\"up\"\n",
    "                elif state==\"up\":\n",
    "                    state=\"down\"\n",
    "                    dl_reps+=1\n",
    "                \n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            cv2.putText(image, \"deadlift\", \n",
    "                           (460,20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            cv2.putText(image, str(dl_reps), \n",
    "                           (500,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        cv2.putText(image, \"down  up\", \n",
    "                           (0,20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "        cv2.putText(image, str(down), \n",
    "                           (10,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "\n",
    "            \n",
    "        cv2.putText(image, str(up), \n",
    "                           (110,60), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "        cv2.putText(image, state, \n",
    "                           (500,100), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                                )\n",
    "            # Render detections\n",
    "        mp_drawing.draw_landmarks(image, position.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )               \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('1'):\n",
    "            excrs=1\n",
    "        if cv2.waitKey(10) & 0xFF == ord('2'):\n",
    "            excrs=2\n",
    "        if cv2.waitKey(10) & 0xFF == ord('3'):\n",
    "            excrs=3\n",
    "            \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
